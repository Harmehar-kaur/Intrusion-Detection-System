{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00f0dec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import ttk\n",
    "from tkinter import messagebox\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from PIL import Image, ImageTk\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc3278d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pmap = {'icmp': 0, 'tcp': 1, 'udp': 2}\n",
    "fmap = {'SF': 0, 'S0': 1, 'REJ': 2, 'RSTR': 3, 'RSTO': 4, 'SH': 5, 'S1': 6, 'S2': 7, 'RSTOS0': 8, 'S3': 9, 'OTH': 10}\n",
    "attacks_types = {\n",
    "    'normal': 'normal', 'back': 'dos', 'buffer_overflow': 'u2r', 'ftp_write': 'r2l',\n",
    "    'guess_passwd': 'r2l', 'imap': 'r2l', 'ipsweep': 'probe', 'land': 'dos',\n",
    "    'loadmodule': 'u2r', 'multihop': 'r2l', 'neptune': 'dos', 'nmap': 'probe',\n",
    "    'perl': 'u2r', 'phf': 'r2l', 'pod': 'dos', 'portsweep': 'probe',\n",
    "    'rootkit': 'u2r', 'satan': 'probe', 'smurf': 'dos', 'spy': 'r2l',\n",
    "    'teardrop': 'dos', 'warezclient': 'r2l', 'warezmaster': 'r2l'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df66ee32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['duration', 'protocol_type', 'service', 'flag', 'src_bytes', 'dst_bytes', 'land', 'wrong_fragment', 'urgent', 'hot', 'num_failed_logins', 'logged_in', 'num_compromised', 'root_shell', 'su_attempted', 'num_root', 'num_file_creations', 'num_shells', 'num_access_files', 'num_outbound_cmds', 'is_host_login', 'is_guest_login', 'count', 'srv_count', 'serror_rate', 'srv_serror_rate', 'rerror_rate', 'srv_rerror_rate', 'same_srv_rate', 'diff_srv_rate', 'srv_diff_host_rate', 'dst_host_count', 'dst_host_srv_count', 'dst_host_same_srv_rate', 'dst_host_diff_srv_rate', 'dst_host_same_src_port_rate', 'dst_host_srv_diff_host_rate', 'dst_host_serror_rate', 'dst_host_srv_serror_rate', 'dst_host_rerror_rate', 'dst_host_srv_rerror_rate', 'target']\n",
      "42\n"
     ]
    }
   ],
   "source": [
    "cols = \"\"\"duration,\n",
    "protocol_type,\n",
    "service,\n",
    "flag,\n",
    "src_bytes,\n",
    "dst_bytes,\n",
    "land,\n",
    "wrong_fragment,\n",
    "urgent,\n",
    "hot,\n",
    "num_failed_logins,\n",
    "logged_in,\n",
    "num_compromised,\n",
    "root_shell,\n",
    "su_attempted,\n",
    "num_root,\n",
    "num_file_creations,\n",
    "num_shells,\n",
    "num_access_files,\n",
    "num_outbound_cmds,\n",
    "is_host_login,\n",
    "is_guest_login,\n",
    "count,\n",
    "srv_count,\n",
    "serror_rate,\n",
    "srv_serror_rate,\n",
    "rerror_rate,\n",
    "srv_rerror_rate,\n",
    "same_srv_rate,\n",
    "diff_srv_rate,\n",
    "srv_diff_host_rate,\n",
    "dst_host_count,\n",
    "dst_host_srv_count,\n",
    "dst_host_same_srv_rate,\n",
    "dst_host_diff_srv_rate,\n",
    "dst_host_same_src_port_rate,\n",
    "dst_host_srv_diff_host_rate,\n",
    "dst_host_serror_rate,\n",
    "dst_host_srv_serror_rate,\n",
    "dst_host_rerror_rate,\n",
    "dst_host_srv_rerror_rate\"\"\"\n",
    "\n",
    "# Parse the columns string to extract valid column names\n",
    "columns = []\n",
    "for c in cols.split(','):\n",
    "    if c.strip():\n",
    "        columns.append(c.strip())\n",
    "\n",
    "# Append the target column name to the list of columns\n",
    "columns.append('target')\n",
    "\n",
    "# Print the list of columns and its length\n",
    "print(columns)\n",
    "print(len(columns))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35593369",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read dataset and perform preprocessing\n",
    "def preprocess_dataset(dataset_path):\n",
    "    dataset_path = \"C:\\\\Users\\\\Harmehar\\\\Desktop\\\\Intrusion-Detection-System\\\\dataset\\\\kddcup.data_10_percent.gz\"\n",
    "    df = pd.read_csv(dataset_path, names=columns)\n",
    "    df['Attack Type'] = df.target.apply(lambda r: attacks_types[r[:-1]])\n",
    "    \n",
    "    # Adding Attack Type column based on the target column\n",
    "    df['Attack Type'] = df.target.apply(lambda r: attacks_types[r[:-1]])\n",
    "\n",
    "    # Drop columns with NaN values and keep columns with more than 1 unique value\n",
    "    df = df.dropna(axis='columns')\n",
    "    df = df[[col for col in df if df[col].nunique() > 1]]\n",
    "\n",
    "    # Remove highly correlated features\n",
    "    df.drop(['num_root', 'srv_serror_rate', 'srv_rerror_rate', 'dst_host_srv_serror_rate',\n",
    "             'dst_host_serror_rate', 'dst_host_rerror_rate', 'dst_host_srv_rerror_rate',\n",
    "             'dst_host_same_srv_rate'], axis=1, inplace=True)\n",
    "\n",
    "    # Feature mapping for categorical variables\n",
    "    df['protocol_type'] = df['protocol_type'].map(pmap)\n",
    "    df['flag'] = df['flag'].map(fmap)\n",
    "\n",
    "    # Drop 'service' column\n",
    "    df.drop('service', axis=1, inplace=True)\n",
    "\n",
    "    # Split data into features (X) and target (Y)\n",
    "    Y = df[['Attack Type']]\n",
    "    X = df.drop(['Attack Type', 'target'], axis=1)\n",
    "\n",
    "    # Scale the features using Min-Max Scaling\n",
    "    scaler = MinMaxScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    # Split data into training and testing sets\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X_scaled, Y, test_size=0.33, random_state=42)\n",
    "\n",
    "    # Return preprocessed data\n",
    "    X_train, X_test, Y_train, Y_test\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71b6c19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the selected model on the dataset\n",
    "def train_model(model_name, X_train, Y_train):\n",
    "    if model_name == 'Naive Bayes':\n",
    "        model = GaussianNB()\n",
    "    elif model_name == 'Decision Tree':\n",
    "        model = DecisionTreeClassifier(criterion=\"entropy\", max_depth=4)\n",
    "    elif model_name == 'Random Forest':\n",
    "        model = RandomForestClassifier(n_estimators=30)\n",
    "    elif model_name == 'SVM':\n",
    "        model = SVC(gamma='scale')\n",
    "    elif model_name == 'Logistic Regression':\n",
    "        model = LogisticRegression(max_iter=1200000)\n",
    "    elif model_name == 'Gradient Boosting':\n",
    "        model = GradientBoostingClassifier(random_state=0)\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "    model.fit(X_train, Y_train)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51da68ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict output using the trained model\n",
    "def predict_output(model, input_data):\n",
    "    try:\n",
    "        X = np.array(input_data).reshape(1, -1)\n",
    "        Y_output = model.predict(X)\n",
    "        return Y_output[0]\n",
    "    except Exception as e:\n",
    "        messagebox.showerror(\"Error\", f\"An error occurred during prediction: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98f314d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display selected plot based on analysis feature\n",
    "def display_selected_plot(plot_type):\n",
    "    plot_mapping = {...}\n",
    "    if plot_type in plot_mapping:\n",
    "        title, names, values = plot_mapping[plot_type]\n",
    "        fig = plt.figure(figsize=(6, 4))\n",
    "        plt.bar(names, values)\n",
    "        plt.title(title)\n",
    "        show_plot(fig, title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b1f4725",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_plot(fig, title):\n",
    "    plot_window = tk.Toplevel(root)\n",
    "    plot_window.title(title)\n",
    "    canvas = FigureCanvasTkAgg(fig, master=plot_window)\n",
    "    canvas.draw()\n",
    "    canvas.get_tk_widget().pack(fill=tk.BOTH, expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9374927e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_analysis_result():\n",
    "    selected_feature = selected_analysis_feature.get()\n",
    "    if selected_feature:\n",
    "        # Map selected feature to corresponding plot file name\n",
    "        plot_mapping = {\n",
    "            \"Training Accuracy\": \"training_accuracy_plot.png\",\n",
    "            \"Testing Accuracy\": \"test_accuracy_plot.png\",\n",
    "            \"Training Time\": \"train_time_plot.png\",\n",
    "            \"Testing Time\": \"test_time_plot.png\"\n",
    "        }\n",
    "\n",
    "        # Get the filename of the selected plot\n",
    "        plot_filename = plot_mapping.get(selected_feature)\n",
    "        if plot_filename:\n",
    "            # Check if the plot file exists\n",
    "            if os.path.exists(plot_filename):\n",
    "                # Open and display the plot image\n",
    "                image = Image.open(plot_filename)\n",
    "                image = image.resize((400, 300), Image.LANCZOS)  # Resize image for display\n",
    "                photo = ImageTk.PhotoImage(image)\n",
    "\n",
    "                # Update the image in the analysis result label\n",
    "                analysis_result_label.configure(image=photo)\n",
    "                analysis_result_label.image = photo  # Keep reference to avoid garbage collection\n",
    "            else:\n",
    "                print(f\"Plot file '{plot_filename}' not found.\")\n",
    "        else:\n",
    "            print(f\"No plot available for the selected feature: {selected_feature}\")\n",
    "    else:\n",
    "        print(\"Please select an analysis feature.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b98de877",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import joblib\n",
    "\n",
    "def submit_model_training():\n",
    "    selected_model = selected_training_model.get()\n",
    "    selected_dataset = selected_training_dataset.get()\n",
    "    \n",
    "    if selected_model and selected_dataset:\n",
    "        dataset_path = \"C:\\\\Users\\\\Harmehar\\\\Desktop\\\\Intrusion-Detection-System\\\\dataset\\\\kddcup.data_10_percent.gz\" \n",
    "        df = preprocess_dataset(dataset_path)\n",
    "        \n",
    "        Y = df[['Attack Type']]\n",
    "        X = df.drop(['Attack Type', 'target'], axis=1)\n",
    "        \n",
    "        sc = MinMaxScaler()\n",
    "        X = sc.fit_transform(X)\n",
    "        \n",
    "        X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.33, random_state=42)\n",
    "        \n",
    "        trained_model = train_model(selected_model, X_train, Y_train.values.ravel())\n",
    "        if trained_model:\n",
    "            # Specify the directory and filename for saving the trained model\n",
    "            trained_model_dir = \"C:\\\\Users\\\\Harmehar\\\\Desktop\\\\Intrusion-Detection-System\\\\trained-model\"\n",
    "            trained_model_path = os.path.join(trained_model_dir, \"trained_model.pkl\")\n",
    "            \n",
    "            # Create the directory if it doesn't exist\n",
    "            os.makedirs(trained_model_dir, exist_ok=True)\n",
    "            \n",
    "            # Save the trained model to the specified path\n",
    "            joblib.dump(trained_model, trained_model_path)\n",
    "            \n",
    "            messagebox.showinfo(\"Model Training\", f\"Training completed using {selected_model} on {selected_dataset}.\")\n",
    "            \n",
    "            # Enable test button and change input fields to dataset dropdown\n",
    "            button_test_model.config(state=tk.NORMAL)\n",
    "            dataset_dropdown.config(state=\"readonly\")  # Change to readonly state for dataset selection\n",
    "    else:\n",
    "        messagebox.showwarning(\"Warning\", \"Please select dataset and model for training.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b86d4966",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_model_testing(model, input_data):\n",
    "    try:\n",
    "        X = input_data.reshape(1, -1)\n",
    "        predicted_output = model.predict(X)\n",
    "        return predicted_output[0]\n",
    "    except Exception as e:\n",
    "        messagebox.showerror(\"Error\", f\"An error occurred during prediction: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "28b55f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_trained_model():\n",
    "    selected_dataset = selected_training_dataset.get()\n",
    "    \n",
    "    if selected_dataset:\n",
    "        # Load the trained model\n",
    "        trained_model_path = \"C:\\\\Users\\\\Harmehar\\\\Desktop\\\\Intrusion-Detection-System\\\\trained-model\\\\trained_model.pkl\"\n",
    "        \n",
    "        try:\n",
    "            trained_model = joblib.load(trained_model_path)\n",
    "            \n",
    "            dataset_path = \"C:\\\\Users\\\\Harmehar\\\\Desktop\\\\Intrusion-Detection-System\\\\dataset\\\\kddcup.data_10_percent.gz\"\n",
    "            df = preprocess_dataset(dataset_path)\n",
    "            \n",
    "            # Use the trained model to make predictions on the test dataset\n",
    "            predictions = perform_model_testing(trained_model, df)  # Use perform_model_testing for prediction\n",
    "            \n",
    "            # Show the results or use the predictions as needed\n",
    "            messagebox.showinfo(\"Test Model\", \"Testing the trained model.\")\n",
    "        except FileNotFoundError:\n",
    "            messagebox.showerror(\"Error\", \"Trained model file not found.\")\n",
    "        except Exception as e:\n",
    "            messagebox.showerror(\"Error\", f\"An error occurred during testing: {str(e)}\")\n",
    "    else:\n",
    "        messagebox.showwarning(\"Warning\", \"Please select a dataset for testing.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9c7bb7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_prediction_test(X_train, Y_train):\n",
    "    try:\n",
    "        input_data = []\n",
    "        all_entries = basic_features_frame.winfo_children() + network_features_frame.winfo_children()\n",
    "        for widget in all_entries:\n",
    "            if isinstance(widget, ttk.Entry):\n",
    "                value = float(widget.get()) if widget.get().strip().replace('.', '', 1).isdigit() else 0.0\n",
    "                input_data.append(value)\n",
    "\n",
    "        selected_model = selected_model_test.get()\n",
    "\n",
    "        model = train_model(selected_model, X_train, Y_train.ravel())\n",
    "        if model:\n",
    "            predicted_output = predict_output(model, input_data)\n",
    "            messagebox.showinfo(\"Prediction Result\", f\"Predicted Output (Y): {predicted_output}\")\n",
    "    except Exception as e:\n",
    "        messagebox.showerror(\"Error\", f\"An error occurred during prediction: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8a5d3cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = tk.Tk()\n",
    "root.title(\"Intrusion Detection System Analysis\")\n",
    "\n",
    "# Create a notebook (tabbed interface)\n",
    "notebook = ttk.Notebook(root)\n",
    "notebook.pack(pady=10, fill='both', expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5b84a887",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Third tab: \"Model Training\"\n",
    "model_training_frame = ttk.Frame(notebook)\n",
    "notebook.add(model_training_frame, text='Model Training')\n",
    "\n",
    "# Create frames for training and testing\n",
    "training_frame = ttk.LabelFrame(model_training_frame, text='Train Model')\n",
    "training_frame.grid(row=0, column=0, padx=10, pady=10, sticky='nsew')\n",
    "\n",
    "testing_frame = ttk.LabelFrame(model_training_frame, text='Test Model')\n",
    "testing_frame.grid(row=0, column=1, padx=10, pady=10, sticky='nsew')\n",
    "\n",
    "# Dropdown for selecting model (under training frame)\n",
    "selected_training_model = tk.StringVar()\n",
    "model_training_options = [\"Naive Bayes\", \"Decision Tree\", \"Random Forest\", \"SVM\", \"Logistic Regression\", \"Gradient Boosting\"]\n",
    "model_training_dropdown = ttk.OptionMenu(training_frame, selected_training_model, *model_training_options)\n",
    "model_training_dropdown.grid(row=0, column=0, padx=10, pady=10)\n",
    "\n",
    "# Dropdown for selecting dataset (under training frame)\n",
    "selected_training_dataset = tk.StringVar(value=\"kdd\")  # Default dataset selection\n",
    "dataset_options = [\"kdd\", \"other_dataset_1\", \"other_dataset_2\"]  # Add more dataset options\n",
    "dataset_dropdown = ttk.Combobox(training_frame, textvariable=selected_training_dataset, values=dataset_options, state=\"disabled\")\n",
    "dataset_dropdown.grid(row=0, column=1, padx=10, pady=10)\n",
    "\n",
    "# Button to submit model training (under training frame)\n",
    "train_button = ttk.Button(training_frame, text=\"Train Model\", command=submit_model_training)\n",
    "train_button.grid(row=1, column=0, columnspan=2, padx=10, pady=10)\n",
    "\n",
    "# Entries for testing input (under testing frame)\n",
    "# Replace testing entries with dataset dropdown after training\n",
    "label = ttk.Label(testing_frame, text=\"Select Dataset:\")\n",
    "label.grid(row=0, column=0, padx=10, pady=5, sticky='w')\n",
    "dataset_dropdown_test = ttk.Combobox(testing_frame, textvariable=selected_training_dataset, values=dataset_options, state=\"readonly\")\n",
    "dataset_dropdown_test.grid(row=0, column=1, padx=10, pady=5)\n",
    "\n",
    "# Button to test the trained model (under testing frame)\n",
    "button_test_model = ttk.Button(testing_frame, text=\"Test Model\", command=test_trained_model, state=tk.DISABLED)\n",
    "button_test_model.grid(row=1, column=0, columnspan=2, pady=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4815a1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# First tab: \"Test Yourself\"\n",
    "test_yourself_frame = ttk.Frame(notebook)\n",
    "notebook.add(test_yourself_frame, text='Test Yourself')\n",
    "\n",
    "# Create frames for basic features, network features, and model selection\n",
    "basic_features_frame = ttk.LabelFrame(test_yourself_frame, text='Basic Features')\n",
    "basic_features_frame.grid(row=0, column=0, padx=10, pady=10, sticky='nsew')\n",
    "\n",
    "network_features_frame = ttk.LabelFrame(test_yourself_frame, text='Network Features')\n",
    "network_features_frame.grid(row=0, column=1, padx=10, pady=10, sticky='nsew')\n",
    "\n",
    "model_selection_frame = ttk.LabelFrame(test_yourself_frame, text='Model Selection')\n",
    "model_selection_frame.grid(row=0, column=2, padx=10, pady=10, sticky='nsew')\n",
    "\n",
    "# Populate basic features frame (example)\n",
    "basic_features = [\"duration\", \"protocol_type\", \"service\", \"flag\", \"src_bytes\", \"dst_bytes\", \"land\", \"wrong_fragment\",\n",
    "                   \"urgent\", \"hot\", \"num_failed_logins\", \"logged_in\", \"num_compromised\", \"root_shell\", \"su_attempted\"]\n",
    "\n",
    "for idx, feature in enumerate(basic_features):\n",
    "    label = ttk.Label(basic_features_frame, text=feature)\n",
    "    label.grid(row=idx, column=0, padx=5, pady=2, sticky='w')\n",
    "    entry = ttk.Entry(basic_features_frame, width=10)\n",
    "    entry.grid(row=idx, column=1, padx=5, pady=2)\n",
    "\n",
    "# Populate network features frame (example)\n",
    "network_features = [\"num_root\", \"num_file_creations\", \"num_shells\", \"num_access_files\", \"num_outbound_cmds\",\n",
    "                    \"is_host_login\", \"is_guest_login\", \"count\", \"srv_count\", \"serror_rate\", \"srv_serror_rate\",\n",
    "                    \"rerror_rate\", \"srv_rerror_rate\", \"same_srv_rate\", \"diff_srv_rate\", \"srv_diff_host_rate\",\n",
    "                    \"dst_host_count\", \"dst_host_srv_count\", \"dst_host_same_srv_rate\", \"dst_host_diff_srv_rate\",\n",
    "                    \"dst_host_same_src_port_rate\", \"dst_host_srv_diff_host_rate\", \"dst_host_serror_rate\",\n",
    "                    \"dst_host_srv_serror_rate\", \"dst_host_rerror_rate\", \"dst_host_srv_rerror_rate\"]\n",
    "\n",
    "# Calculate number of rows and columns for network features layout\n",
    "num_rows = (len(network_features) + 1) // 2\n",
    "for idx, feature in enumerate(network_features):\n",
    "    label = ttk.Label(network_features_frame, text=feature)\n",
    "    col = idx % 2\n",
    "    row = idx // 2\n",
    "    label.grid(row=row, column=col * 2, padx=5, pady=2, sticky='w')\n",
    "    entry = ttk.Entry(network_features_frame, width=10)\n",
    "    entry.grid(row=row, column=col * 2 + 1, padx=5, pady=2)\n",
    "    \n",
    "# Model selection dropdown and Predict button within model selection frame\n",
    "model_options = [\"Naive Bayes\", \"Decision Tree\", \"Random Forest\", \"SVM\", \"Logistic Regression\", \"Gradient Boosting\"]\n",
    "selected_model_test = tk.StringVar(model_selection_frame)\n",
    "selected_model_test.set(\"Select Model\")\n",
    "\n",
    "model_menu = ttk.OptionMenu(model_selection_frame, selected_model_test, *model_options)\n",
    "model_menu.grid(row=0, column=0, padx=5, pady=5)\n",
    "\n",
    "button_predict_test = ttk.Button(model_selection_frame, text=\"Predict Output (Y)\", command=perform_prediction_test)\n",
    "button_predict_test.grid(row=1, column=0, padx=5, pady=5)\n",
    "\n",
    "# Configure weights for row and column resizing within the test_yourself_frame\n",
    "test_yourself_frame.columnconfigure((0, 1, 2), weight=1)\n",
    "test_yourself_frame.rowconfigure(0, weight=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "08bb2ee2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Second tab: \"Analysis Results\"\n",
    "analysis_results_frame = ttk.Frame(notebook)\n",
    "notebook.add(analysis_results_frame, text='Analysis Results')\n",
    "\n",
    "# Dropdown for selecting analysis feature\n",
    "selected_analysis_feature = tk.StringVar()\n",
    "analysis_feature_options = [\"Training Accuracy\", \"Testing Accuracy\", \"Training Time\", \"Testing Time\"]\n",
    "analysis_dropdown = ttk.OptionMenu(analysis_results_frame, selected_analysis_feature, *analysis_feature_options)\n",
    "analysis_dropdown.pack(padx=10, pady=10)\n",
    "\n",
    "# Button to display selected analysis feature\n",
    "analysis_button = ttk.Button(analysis_results_frame, text=\"Show Analysis\", command=collect_analysis_result)\n",
    "analysis_button.pack(padx=10, pady=10)\n",
    "\n",
    "# Label to display analysis result (image)\n",
    "analysis_result_label = ttk.Label(analysis_results_frame)\n",
    "analysis_result_label.pack(padx=10, pady=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ed6f34e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the Tkinter main loop\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc76a9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a20bbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e19ff5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16d3940",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
